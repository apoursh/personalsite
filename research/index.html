<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <!--<title>Bare - Start Bootstrap Template</title>-->

    <!-- Bootstrap core CSS -->
    <link href="../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <style>
      body {
        padding-top: 54px;
      }
      @media (min-width: 992px) {
        body {
          padding-top: 56px;
        }
      }

    </style>

  </head>

  <body>
    <!-- Page Content -->
    <div class="body"> <!-- test between container and body-->
      <div class="card-header">
        <div class="col-lg-5 text-center">
            <h2> 
            Projects
            </h2>
        </div>
      </div>

      <div class="card-title">
        <div class="col-lg-5 text-center">
            <h5> 
                Projects in Genetics
            </h5>
        </div>
      </div>
    <!-- Decentralized GWAS-->
      <div class="row">
        <div class="col-lg-4 text-right">
            <p class="lead"> 
            Decentralized GWAS
            </br>
            <img src="figs/dgwas.jpeg" alt="gwas" width=220> 
            </p>
        </div>
        <div class ="col-lg-6 text-left">
          <p class="hr">
          </br>
          Genome Wide Association Studies GWAS aim to tease out associtations between single nucleotide polymorphism (SNP) (mutations of a single basepair) and a particular disease or phenotype. Because a phenotype is often influenced by many SNPs, often a large sample size is needed to achieve statistical power. The two common approaches are 1) to gather the required amount of data and analyze the data in one location, or 2) use meta-study techniques. The first approach leads to
          significant loss in privacy of participants and can have other associated costs. The second approach can lead to bias. In this project, we implemented a decentralized end-to-end GWAS pipeline with population structure control via PCA. The manuscript is currently under preparation. 
          </p>
        </div>
      </div>
    <!--PCA in Popgen-->
      <div class="row">
        <div class="col-lg-4 text-right">
            <p class="lead"> 
            Dimensionality reduction in PopGen
            </br>
            <img src="figs/pca.png" alt="PopresPCA" width=220> 
            </p>
        </div>
        <div class ="col-lg-6 text-left">
          <p class="hr">
          </br>
          The picture to the left shows a PCA plot of the Population Reference Sample (POPRES) from Nelson, et. al. 2008 data. Dimensionality reduction algorithms have been a main staple population genetics. PCA is the most common and often most biologically meaningful approach for dimensionality reduction on the genotype matrix (see McVean, 2009). <a href="https://github.com/gabraham/flashpca">Flashpca</a> and <a href="https://www.hsph.harvard.edu/alkes-price/software/">EIGENSOFT</a>
          provide scalable software for performing PCA, however, they do not handle more sophisticated PCA approaches that are often useful to address biases in the data. For and example see McVean, 2009 for how lack fo balance in samples from each region can lead to bias. This project
          aims at producing a software package that interfaces with the common input data formats, addresses the aforementioned bias via, weighted PCA, debiases ancient DNA projections, provides other exploratory dimensionality reduction approaches and works with data collected on different arrays. As opposed to the two aforementioned softwares that aim at biobank size datasets, this package is aimed for use with small and medium size cohorts. The accompanied tutorial will be linked
          here. 
          This project is currently in progress.
          </p>
        </div>
      </div>

    <!--ClinGen-->
      <div class="row">
        <div class="col-lg-4 text-right">
            <p class="lead"> 
            Clinical Genetics
            </br>
            <img src="figs/acmg.png" alt="f3_Jarvik" width=220> 
            </p>
        </div>
        <div class ="col-lg-6 text-left">
          <p class="hr">
          </br>
          text text 
          </p>
        </div>
        <hr>
      </div>


      <div class="row">
        <div class="col-lg-5 text-center">
            <h5> 
            Networks in biology
            </h5>
        </div>
        <hr>
        </br>
      </div>
 
      
    <!--Denoising-->
      <div class="row">
        <div class="col-lg-4 text-right">
            <p class="lead">
            Computational Denoising
            </br>
            <img src="figs/network.png" alt="Network From NE" width=200> 
            </p>
        </div>
        <div class ="col-lg-6 text-left">
          <p class="hr">
          </br>
          For many biological datasets, Networks provide a nice abstraction of the dynamics and relations between the pieces. Biological data is often noisy, due to both biological and technical noise. Reducing the noise, if possible, can be costly. On the other hand, working with noisy data can lead to inaccurate conclusions. One remedy is to use biological intuition to denoise the data. I've been involved with two projects in computational denoising of biological data.
          </br>
          My main contribution is in developing <a href="https://www.biorxiv.org/content/biorxiv/early/2018/05/09/317941.full.pdf">Network Enhancement</a>. (to appear in Nature Communications) we used a combination of diffusion and regularization for denoising generic biological networks. The intuition for diffusion is that in biology two elements being closed to the same element often implies that the initial two elements are close. On the other hand, regularization leads to a more sparse network and controls the scale. We show that mathematically, our algorithm leads to a "smoothed out" PCA, meaning that smaller singular
          values are shrunk more aggressively.
          </br>
            I've also been involved in developing a Hi-C network denoising algorithm presented <a href="http://papers.nips.cc/paper/6291-unsupervised-learning-from-noisy-networks-with-applications-to-hi-c-data.pdf">here</a>. 

          </p>
        </div>
      </div>
 
    <!--microbiom-->
      <div class="row">
        <div class="col-lg-4 text-right">
            <p class="lead">
            Microbiom
            </br>
            <img src="figs/network.png" alt="Network From NE" width=200> 
            </p>
        </div>
        <div class ="col-lg-6 text-left">
          <p class="hr">
          </br>
          text text 
          </p>
        </div>
      </div>
 
    </div>

    <hr>

    <div class="row">
        <div class="col-lg-5 text-center">
            <h5> 
                Previous research (Physics)
            </h5>
        </div>
        <hr>

        </br>
    </div>
    <!--physics-->
      <div class="row">
        <div class="col-lg-4 text-right">
            <p class="lead">
            High pressure physics
            </br>
            <img src="figs/Diamond_Anvil_Cell.svg" alt="DAC" width=200> 
            </p>
        </div>
        <div class ="col-lg-6 text-left">
          <p class="hr">
          </br>
          In 1935, Wigner and Huntington proposed that at low temperatures and high pressures, the bonds in hydrogen molecules  destablize leading to formation of atomic hydrogen and thereby metallic hydrogen. This claim, lead to an arms race for constructing metallic hydrogen. Later Ashcroft argued that, once produced, metallic hydrogen could stay superconductive up to room temperature and Isaac Silvera (2010) argued that metallic hydrogen could provide the best rocket fuel. These
          theoretical findings accelerated the importance of experimental discovery of metallic hydrogen.
          </br>
          Prior to starting as a graduate student at Stanford, I took a year off to work in the  <a href="https://projects.iq.harvard.edu/silvera">Silvera Lab</a>, where I learned about low-temperature, high-pressure physics as well as spectroscopy. The picture to the left shows how these high pressures are created. The sample is loaded in the liquid form (at low temperature) in a hole created in a metallic gasket. The sample is then trapped by two dimonds from top and bottom, moving the
          diamonds closer to each other increases the pressure on the sample. 
          </p>
        </div>
      </div>
    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  </body>

</html>
